{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5a9c8b-88ee-4378-bf36-99033f26f432",
   "metadata": {},
   "source": [
    "# Objetivo: Analizar a traves de ejemplos practicos el algoritmo de Aumento de Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d53108-5369-4290-9467-90bcf92e6abf",
   "metadata": {},
   "source": [
    "## Algoritmo Aumento de Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154f2ac-e9a1-4d20-9ac9-26ac05b6ac70",
   "metadata": {},
   "source": [
    "Los clasificadores de aumento de gradiente son un grupo de algoritmos de Machine Learning que combinan muchos modelos de aprendizaje débiles para crear un modelo predictivo sólido. Los árboles de decisión se utilizan generalmente cuando se realiza un aumento de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad87f57-7222-4bfd-ad2f-6fe40a9f5c57",
   "metadata": {},
   "source": [
    "La biblioteca de Machine Learning de Python, Scikit-Learn , admite diferentes implementaciones de clasificadores que aumentan el gradiente, incluido XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750b78b-40c4-4703-9287-d2aa72b645a2",
   "metadata": {},
   "source": [
    "Repasaremos la teoría detrás de los modelos / clasificadores de aumento de gradiente y veremos dos formas diferentes de realizar la clasificación con clasificadores de aumento de gradiente en Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1f1be-fac6-4745-82fa-ac0c46a09150",
   "metadata": {},
   "source": [
    "## Definición de términos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8dd03e-8da3-4d23-a61d-e9c39bcb15e4",
   "metadata": {},
   "source": [
    "Para empezar, ¿qué es la clasificación? En el Machine Learning, hay dos tipos de problemas de aprendizaje supervisado : clasificación y regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960547ea-7cda-42b9-a509-a72ebdcdd218",
   "metadata": {},
   "source": [
    "La clasificación se refiere a la tarea de otorgar características a un algoritmo de Machine Learning y hacer que el algoritmo coloque las instancias / puntos de datos en una de las muchas clases discretas. Las clases son de naturaleza categórica, no es posible que una instancia se clasifique como parcialmente una clase y parcialmente otra. Un ejemplo clásico de una tarea de clasificación es clasificar los correos electrónicos como «spam» o «no spam»; no hay un correo electrónico «un poco spam»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc623d-372f-45d2-b57a-35d238c3d48c",
   "metadata": {},
   "source": [
    "Las regresiones se realizan cuando la salida del modelo de Machine Learning es un valor real o un valor continuo. Un ejemplo de estos valores continuos sería «peso» o «longitud». Un ejemplo de una tarea de regresión es predecir la edad de una persona en función de características como altura, peso, ingresos, etc.\n",
    "\n",
    "Los clasificadores de aumento de gradiente son tipos específicos de algoritmos que se utilizan para tareas de clasificación, como sugiere su nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4f26b-3598-4e3f-bf13-f7a15f68b70d",
   "metadata": {},
   "source": [
    "Las características son las entradas que se le dan al algoritmo de Machine Learning, las entradas que se utilizarán para calcular un valor de salida. En un sentido matemático, las características del conjunto de datos son las variables utilizadas para resolver la ecuación. La otra parte de la ecuación es la etiqueta o el objetivo, que son las clases en las que se categorizarán las instancias. Debido a que las etiquetas contienen los valores objetivo para el clasificador de Machine Learning, al entrenar un clasificador, debe dividir los datos en conjuntos de entrenamiento y prueba. El conjunto de entrenamiento tendrá objetivos / etiquetas, mientras que el conjunto de prueba no contendrá estos valores.\n",
    "\n",
    "Scikit-Learn, o «sklearn», es una biblioteca de Machine Learning creada para Python, destinada a acelerar las tareas de Machine Learning al facilitar la implementación de algoritmos de Machine Learning. Tiene funciones fáciles de usar para ayudar a dividir datos en conjuntos de entrenamiento y prueba, así como a entrenar un modelo, hacer predicciones y evaluar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c9f52-fc02-4493-adbc-0919da2b6c71",
   "metadata": {},
   "source": [
    "## Cómo surgió el aumento de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c2be3-6874-4524-86b9-3ca327ece396",
   "metadata": {},
   "source": [
    "La idea detrás del «aumento de gradiente» es tomar una hipótesis débil o un algoritmo de aprendizaje débil y hacer una serie de ajustes que mejorarán la solidez de la hipótesis / alumno. Este tipo de Impulso de hipótesis se basa en la idea de Probabilidad Aproximadamente Aprendizaje Correcto (PAC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48c1fe-6ee9-4e3c-b1f1-b81b5cdea948",
   "metadata": {},
   "source": [
    "Este método de aprendizaje PAC investiga problemas de Machine Learning para interpretar qué tan complejos son, y se aplica un método similar a Hypothesis Boosting.\n",
    "\n",
    "En el refuerzo de hipótesis, observa todas las observaciones en las que se entrena el algoritmo de Machine Learning y deja solo las observaciones que el método de Machine Learning clasificó con éxito, eliminando las otras observaciones. Se crea un nuevo alumno débil y se prueba en el conjunto de datos que se clasificaron de manera deficiente, y luego solo se conservan los ejemplos que se clasificaron con éxito.\n",
    "\n",
    "Esta idea se realizó en el algoritmo Adaptive Boosting (AdaBoost). Para AdaBoost, muchos aprendices débiles se crean inicializando muchos algoritmos de árbol de decisión que solo tienen una sola división, como el «muñón» en la imagen de abajo.\n",
    "\n",
    "El algoritmo pondera las instancias / observaciones en el conjunto de entrenamiento y se asigna más peso a las instancias que son difíciles de clasificar. Los alumnos más débiles se agregan al sistema secuencialmente y se les asigna a las instancias de capacitación más difíciles.\n",
    "\n",
    "En AdaBoost, las predicciones se realizan por mayoría de votos, y las instancias se clasifican según la clase que recibe la mayor cantidad de votos de los estudiantes débiles.\n",
    "\n",
    "Los clasificadores de aumento de gradiente son el método AdaBoosting combinado con minimización ponderada, después de lo cual se recalculan los clasificadores y las entradas ponderadas. El objetivo de los clasificadores Gradient Boosting es minimizar la pérdida o la diferencia entre el valor de clase real del ejemplo de entrenamiento y el valor de clase predicho. No es necesario comprender el proceso para reducir la pérdida del clasificador, pero funciona de manera similar al descenso de gradiente en una red neuronal.\n",
    "\n",
    "Se realizaron refinamientos en este proceso y se crearon máquinas de aumento de gradiente .\n",
    "\n",
    "En el caso de Gradient Boosting Machines, cada vez que se agrega un nuevo alumno débil al modelo, los pesos de los aprendices anteriores se congelan o cementan en su lugar, sin cambios a medida que se introducen las nuevas capas. Esto es distinto de los enfoques utilizados en AdaBoosting donde los valores se ajustan cuando se agregan nuevos alumnos.\n",
    "\n",
    "El poder de las máquinas de aumento de gradiente proviene del hecho de que se pueden usar en más problemas de clasificación binaria, se pueden usar en problemas de clasificación de clases múltiples e incluso problemas de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54329e03-b6d8-497f-8012-5c4fcf6a3312",
   "metadata": {},
   "source": [
    "## Teoría detrás de Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dec52c-79c7-44eb-af40-22c240cc25e7",
   "metadata": {},
   "source": [
    "El clasificador de aumento de gradiente depende de una función de pérdida . Se puede utilizar una función de pérdida personalizada, y muchas funciones de pérdida estandarizadas son compatibles con clasificadores de aumento de gradiente, pero la función de pérdida tiene que ser diferenciable.\n",
    "\n",
    "Los algoritmos de clasificación utilizan con frecuencia pérdidas logarítmicas, mientras que los algoritmos de regresión pueden utilizar errores al cuadrado. Los sistemas de aumento de gradiente no tienen que derivar una nueva función de pérdida cada vez que se agrega el algoritmo de aumento, sino que se puede aplicar al sistema cualquier función de pérdida diferenciable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4b59a-b1ad-4adb-ac62-e5a1cdac04fe",
   "metadata": {},
   "source": [
    "Los sistemas de aumento de gradiente tienen otras dos partes necesarias: un alumno débil y un componente aditivo. Los sistemas de aumento de gradiente utilizan árboles de decisión como sus aprendices débiles. Los árboles de regresión se utilizan para los estudiantes débiles, y estos árboles de regresión generan valores reales. Debido a que los resultados son valores reales, a medida que se agregan nuevos estudiantes al modelo, los resultados de los árboles de regresión se pueden sumar para corregir los errores en las predicciones.\n",
    "\n",
    "El componente aditivo de un modelo de aumento de gradiente proviene del hecho de que los árboles se agregan al modelo con el tiempo, y cuando esto ocurre, los árboles existentes no se manipulan, sus valores permanecen fijos.\n",
    "\n",
    "Se utiliza un procedimiento similar al descenso de gradiente para minimizar el error entre parámetros dados. Esto se hace tomando la pérdida calculada y realizando un descenso de gradiente para reducir esa pérdida. Posteriormente, se modifican los parámetros del árbol para reducir la pérdida residual.\n",
    "\n",
    "La salida del nuevo árbol se agrega luego a la salida de los árboles anteriores utilizados en el modelo. Este proceso se repite hasta que se alcanza un número de árboles previamente especificado, o la pérdida se reduce por debajo de un cierto umbral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e908b7-bf3c-4aac-93c7-d8f652d4fb51",
   "metadata": {},
   "source": [
    "## Pasos para aumentar el gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984f329-9f4e-4919-b662-1a42fb7f3946",
   "metadata": {},
   "source": [
    "Para implementar un clasificador de aumento de gradiente, necesitaremos llevar a cabo una serie de pasos diferentes. Necesitaremos:\n",
    "\n",
    "* Encajar el modelo\n",
    "* Ajustar los parámetros y los hiperparámetros del modelo\n",
    "* Hacer predicciones\n",
    "* Interpreta los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499e510-37fb-40de-8191-2ff85dc682b7",
   "metadata": {},
   "source": [
    "Ajustar modelos con Scikit-Learn es bastante fácil, ya que normalmente solo tenemos que llamar al fit()comando después de configurar el modelo.\n",
    "\n",
    "Sin embargo, ajustar los hiperparámetros del modelo requiere una toma de decisiones activa de nuestra parte. Hay varios argumentos / hiperparámetros que podemos ajustar para intentar obtener la mejor precisión para el modelo. Una de las formas en que podemos hacer esto es alterando la tasa de aprendizaje del modelo. Queremos comprobar el rendimiento del modelo en el conjunto de entrenamiento a diferentes velocidades de aprendizaje y luego usar la mejor velocidad de aprendizaje para hacer predicciones.\n",
    "\n",
    "Las predicciones se pueden hacer en Scikit-Learn de manera muy simple usando la predict()función después de ajustar el clasificador. Querrá predecir las características del conjunto de datos de prueba y luego comparar las predicciones con las etiquetas reales. El proceso de evaluación de un clasificador generalmente implica verificar la precisión del clasificador y luego ajustar los parámetros / hiperparámetros del modelo hasta que el clasificador tenga una precisión con la que el usuario esté satisfecho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da43d4-b586-4e3b-8def-8c0516253180",
   "metadata": {},
   "source": [
    "## Diferentes clasificadores de aumento de gradiente mejorados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a131a5-bb7d-4538-8b08-1f4087fed9e8",
   "metadata": {},
   "source": [
    "#### Aprendizaje penalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97da48-db5b-4db4-9705-7126d88183cd",
   "metadata": {},
   "source": [
    "Se pueden utilizar ciertas restricciones para evitar el sobreajuste, según la estructura del árbol de decisiones. El tipo de árbol de decisión que se utiliza en el aumento de gradiente es un árbol de regresión, que tiene valores numéricos como hojas o pesos. Estos valores de peso se pueden regularizar utilizando los diferentes métodos de regularización, como los pesos de regularización L1 o L2, lo que penaliza el algoritmo de refuerzo radiante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb390ce-2b48-44c4-b3c7-4637a4fd8aa7",
   "metadata": {},
   "source": [
    "#### Restricciones de árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419e2dc-11f7-4695-a2ce-a3e47a33bd49",
   "metadata": {},
   "source": [
    "El árbol de decisión se puede restringir de numerosas formas, como limitar la profundidad del árbol, imponer un límite al número de hojas o nodes del árbol, limitar el número de observaciones por división y limitar el número de observaciones entrenadas. En general, cuantas más restricciones utilice al crear árboles, más árboles necesitará el modelo para ajustar correctamente los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b9ab2-360b-44f4-9dc6-e3dab8578766",
   "metadata": {},
   "source": [
    "#### Muestreo aleatorio / Impulso estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531a814-373c-4ef3-83b6-8681708e2e68",
   "metadata": {},
   "source": [
    "Tomar submuestras aleatorias del conjunto de datos de entrenamiento, una técnica conocida como aumento de gradiente estocástico, también puede ayudar a prevenir el sobreajuste. Esta técnica reduce esencialmente la fuerza de la correlación entre árboles.\n",
    "\n",
    "Hay varias formas de submuestrear el conjunto de datos, como submuestrear columnas antes de cada división, submuestrear columnas antes de crear un árbol, como filas de submuestreo antes de crear un árbol. En general, el submuestreo a tasas grandes que no superen el 50% de los datos parece ser beneficioso para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995aa8d-8410-4f84-8eba-49f2a52f8e77",
   "metadata": {},
   "source": [
    "#### Actualizaciones ponderadas / por contracción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d43cf-74cb-4394-8a27-b62a295f3f93",
   "metadata": {},
   "source": [
    "Debido a que las predicciones de cada árbol se suman, las contribuciones de los árboles pueden inhibirse o ralentizarse mediante una técnica llamada contracción. Se ajusta una «tasa de aprendizaje», y cuando se reduce la tasa de aprendizaje, se deben agregar más árboles al modelo. Esto hace que el modelo necesite más tiempo para entrenarse.\n",
    "\n",
    "Existe una compensación entre la tasa de aprendizaje y la cantidad de árboles necesarios, por lo que tendrá que experimentar para encontrar los mejores valores para cada uno de los parámetros, pero los valores pequeños menores a 0.1 o valores entre 0.1 y 0.3 a menudo funcionan bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341daeca-b709-44fa-b7bd-fdcedd0f78d8",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c3e57-a1bd-4ac6-8f78-cfe56688c15f",
   "metadata": {},
   "source": [
    "XGBoost es una versión refinada y personalizada de un sistema de árbol de decisiones que impulsa el gradiente, creado teniendo en cuenta el rendimiento y la velocidad. XGBoost en realidad significa «eXtreme Gradient Boosting» y se refiere al hecho de que los algoritmos y métodos se han personalizado para llevar el límite de lo que es posible para los algoritmos de aumento de gradiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
