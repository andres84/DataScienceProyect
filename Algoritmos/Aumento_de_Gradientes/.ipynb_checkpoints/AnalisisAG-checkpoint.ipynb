{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5a9c8b-88ee-4378-bf36-99033f26f432",
   "metadata": {},
   "source": [
    "# Objetivo: Analizar a traves de ejemplos practicos el algoritmo de Aumento de Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d53108-5369-4290-9467-90bcf92e6abf",
   "metadata": {},
   "source": [
    "## Algoritmo Aumento de Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154f2ac-e9a1-4d20-9ac9-26ac05b6ac70",
   "metadata": {},
   "source": [
    "Los clasificadores de aumento de gradiente son un grupo de algoritmos de Machine Learning que combinan muchos modelos de aprendizaje débiles para crear un modelo predictivo sólido. Los árboles de decisión se utilizan generalmente cuando se realiza un aumento de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad87f57-7222-4bfd-ad2f-6fe40a9f5c57",
   "metadata": {},
   "source": [
    "La biblioteca de Machine Learning de Python, Scikit-Learn , admite diferentes implementaciones de clasificadores que aumentan el gradiente, incluido XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750b78b-40c4-4703-9287-d2aa72b645a2",
   "metadata": {},
   "source": [
    "Repasaremos la teoría detrás de los modelos / clasificadores de aumento de gradiente y veremos dos formas diferentes de realizar la clasificación con clasificadores de aumento de gradiente en Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1f1be-fac6-4745-82fa-ac0c46a09150",
   "metadata": {},
   "source": [
    "## Definición de términos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8dd03e-8da3-4d23-a61d-e9c39bcb15e4",
   "metadata": {},
   "source": [
    "Para empezar, ¿qué es la clasificación? En el Machine Learning, hay dos tipos de problemas de aprendizaje supervisado : clasificación y regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960547ea-7cda-42b9-a509-a72ebdcdd218",
   "metadata": {},
   "source": [
    "La clasificación se refiere a la tarea de otorgar características a un algoritmo de Machine Learning y hacer que el algoritmo coloque las instancias / puntos de datos en una de las muchas clases discretas. Las clases son de naturaleza categórica, no es posible que una instancia se clasifique como parcialmente una clase y parcialmente otra. Un ejemplo clásico de una tarea de clasificación es clasificar los correos electrónicos como «spam» o «no spam»; no hay un correo electrónico «un poco spam»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc623d-372f-45d2-b57a-35d238c3d48c",
   "metadata": {},
   "source": [
    "Las regresiones se realizan cuando la salida del modelo de Machine Learning es un valor real o un valor continuo. Un ejemplo de estos valores continuos sería «peso» o «longitud». Un ejemplo de una tarea de regresión es predecir la edad de una persona en función de características como altura, peso, ingresos, etc.\n",
    "\n",
    "Los clasificadores de aumento de gradiente son tipos específicos de algoritmos que se utilizan para tareas de clasificación, como sugiere su nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4f26b-3598-4e3f-bf13-f7a15f68b70d",
   "metadata": {},
   "source": [
    "Las características son las entradas que se le dan al algoritmo de Machine Learning, las entradas que se utilizarán para calcular un valor de salida. En un sentido matemático, las características del conjunto de datos son las variables utilizadas para resolver la ecuación. La otra parte de la ecuación es la etiqueta o el objetivo, que son las clases en las que se categorizarán las instancias. Debido a que las etiquetas contienen los valores objetivo para el clasificador de Machine Learning, al entrenar un clasificador, debe dividir los datos en conjuntos de entrenamiento y prueba. El conjunto de entrenamiento tendrá objetivos / etiquetas, mientras que el conjunto de prueba no contendrá estos valores.\n",
    "\n",
    "Scikit-Learn, o «sklearn», es una biblioteca de Machine Learning creada para Python, destinada a acelerar las tareas de Machine Learning al facilitar la implementación de algoritmos de Machine Learning. Tiene funciones fáciles de usar para ayudar a dividir datos en conjuntos de entrenamiento y prueba, así como a entrenar un modelo, hacer predicciones y evaluar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c9f52-fc02-4493-adbc-0919da2b6c71",
   "metadata": {},
   "source": [
    "## Cómo surgió el aumento de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c2be3-6874-4524-86b9-3ca327ece396",
   "metadata": {},
   "source": [
    "La idea detrás del «aumento de gradiente» es tomar una hipótesis débil o un algoritmo de aprendizaje débil y hacer una serie de ajustes que mejorarán la solidez de la hipótesis / alumno. Este tipo de Impulso de hipótesis se basa en la idea de Probabilidad Aproximadamente Aprendizaje Correcto (PAC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48c1fe-6ee9-4e3c-b1f1-b81b5cdea948",
   "metadata": {},
   "source": [
    "Este método de aprendizaje PAC investiga problemas de Machine Learning para interpretar qué tan complejos son, y se aplica un método similar a Hypothesis Boosting.\n",
    "\n",
    "En el refuerzo de hipótesis, observa todas las observaciones en las que se entrena el algoritmo de Machine Learning y deja solo las observaciones que el método de Machine Learning clasificó con éxito, eliminando las otras observaciones. Se crea un nuevo alumno débil y se prueba en el conjunto de datos que se clasificaron de manera deficiente, y luego solo se conservan los ejemplos que se clasificaron con éxito.\n",
    "\n",
    "Esta idea se realizó en el algoritmo Adaptive Boosting (AdaBoost). Para AdaBoost, muchos aprendices débiles se crean inicializando muchos algoritmos de árbol de decisión que solo tienen una sola división, como el «muñón» en la imagen de abajo.\n",
    "\n",
    "El algoritmo pondera las instancias / observaciones en el conjunto de entrenamiento y se asigna más peso a las instancias que son difíciles de clasificar. Los alumnos más débiles se agregan al sistema secuencialmente y se les asigna a las instancias de capacitación más difíciles.\n",
    "\n",
    "En AdaBoost, las predicciones se realizan por mayoría de votos, y las instancias se clasifican según la clase que recibe la mayor cantidad de votos de los estudiantes débiles.\n",
    "\n",
    "Los clasificadores de aumento de gradiente son el método AdaBoosting combinado con minimización ponderada, después de lo cual se recalculan los clasificadores y las entradas ponderadas. El objetivo de los clasificadores Gradient Boosting es minimizar la pérdida o la diferencia entre el valor de clase real del ejemplo de entrenamiento y el valor de clase predicho. No es necesario comprender el proceso para reducir la pérdida del clasificador, pero funciona de manera similar al descenso de gradiente en una red neuronal.\n",
    "\n",
    "Se realizaron refinamientos en este proceso y se crearon máquinas de aumento de gradiente .\n",
    "\n",
    "En el caso de Gradient Boosting Machines, cada vez que se agrega un nuevo alumno débil al modelo, los pesos de los aprendices anteriores se congelan o cementan en su lugar, sin cambios a medida que se introducen las nuevas capas. Esto es distinto de los enfoques utilizados en AdaBoosting donde los valores se ajustan cuando se agregan nuevos alumnos.\n",
    "\n",
    "El poder de las máquinas de aumento de gradiente proviene del hecho de que se pueden usar en más problemas de clasificación binaria, se pueden usar en problemas de clasificación de clases múltiples e incluso problemas de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54329e03-b6d8-497f-8012-5c4fcf6a3312",
   "metadata": {},
   "source": [
    "## Teoría detrás de Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dec52c-79c7-44eb-af40-22c240cc25e7",
   "metadata": {},
   "source": [
    "El clasificador de aumento de gradiente depende de una función de pérdida . Se puede utilizar una función de pérdida personalizada, y muchas funciones de pérdida estandarizadas son compatibles con clasificadores de aumento de gradiente, pero la función de pérdida tiene que ser diferenciable.\n",
    "\n",
    "Los algoritmos de clasificación utilizan con frecuencia pérdidas logarítmicas, mientras que los algoritmos de regresión pueden utilizar errores al cuadrado. Los sistemas de aumento de gradiente no tienen que derivar una nueva función de pérdida cada vez que se agrega el algoritmo de aumento, sino que se puede aplicar al sistema cualquier función de pérdida diferenciable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4b59a-b1ad-4adb-ac62-e5a1cdac04fe",
   "metadata": {},
   "source": [
    "Los sistemas de aumento de gradiente tienen otras dos partes necesarias: un alumno débil y un componente aditivo. Los sistemas de aumento de gradiente utilizan árboles de decisión como sus aprendices débiles. Los árboles de regresión se utilizan para los estudiantes débiles, y estos árboles de regresión generan valores reales. Debido a que los resultados son valores reales, a medida que se agregan nuevos estudiantes al modelo, los resultados de los árboles de regresión se pueden sumar para corregir los errores en las predicciones.\n",
    "\n",
    "El componente aditivo de un modelo de aumento de gradiente proviene del hecho de que los árboles se agregan al modelo con el tiempo, y cuando esto ocurre, los árboles existentes no se manipulan, sus valores permanecen fijos.\n",
    "\n",
    "Se utiliza un procedimiento similar al descenso de gradiente para minimizar el error entre parámetros dados. Esto se hace tomando la pérdida calculada y realizando un descenso de gradiente para reducir esa pérdida. Posteriormente, se modifican los parámetros del árbol para reducir la pérdida residual.\n",
    "\n",
    "La salida del nuevo árbol se agrega luego a la salida de los árboles anteriores utilizados en el modelo. Este proceso se repite hasta que se alcanza un número de árboles previamente especificado, o la pérdida se reduce por debajo de un cierto umbral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e908b7-bf3c-4aac-93c7-d8f652d4fb51",
   "metadata": {},
   "source": [
    "## Pasos para aumentar el gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984f329-9f4e-4919-b662-1a42fb7f3946",
   "metadata": {},
   "source": [
    "Para implementar un clasificador de aumento de gradiente, necesitaremos llevar a cabo una serie de pasos diferentes. Necesitaremos:\n",
    "\n",
    "* Encajar el modelo\n",
    "* Ajustar los parámetros y los hiperparámetros del modelo\n",
    "* Hacer predicciones\n",
    "* Interpreta los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499e510-37fb-40de-8191-2ff85dc682b7",
   "metadata": {},
   "source": [
    "Ajustar modelos con Scikit-Learn es bastante fácil, ya que normalmente solo tenemos que llamar al fit()comando después de configurar el modelo.\n",
    "\n",
    "Sin embargo, ajustar los hiperparámetros del modelo requiere una toma de decisiones activa de nuestra parte. Hay varios argumentos / hiperparámetros que podemos ajustar para intentar obtener la mejor precisión para el modelo. Una de las formas en que podemos hacer esto es alterando la tasa de aprendizaje del modelo. Queremos comprobar el rendimiento del modelo en el conjunto de entrenamiento a diferentes velocidades de aprendizaje y luego usar la mejor velocidad de aprendizaje para hacer predicciones.\n",
    "\n",
    "Las predicciones se pueden hacer en Scikit-Learn de manera muy simple usando la predict()función después de ajustar el clasificador. Querrá predecir las características del conjunto de datos de prueba y luego comparar las predicciones con las etiquetas reales. El proceso de evaluación de un clasificador generalmente implica verificar la precisión del clasificador y luego ajustar los parámetros / hiperparámetros del modelo hasta que el clasificador tenga una precisión con la que el usuario esté satisfecho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da43d4-b586-4e3b-8def-8c0516253180",
   "metadata": {},
   "source": [
    "## Diferentes clasificadores de aumento de gradiente mejorados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a131a5-bb7d-4538-8b08-1f4087fed9e8",
   "metadata": {},
   "source": [
    "#### Aprendizaje penalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97da48-db5b-4db4-9705-7126d88183cd",
   "metadata": {},
   "source": [
    "Se pueden utilizar ciertas restricciones para evitar el sobreajuste, según la estructura del árbol de decisiones. El tipo de árbol de decisión que se utiliza en el aumento de gradiente es un árbol de regresión, que tiene valores numéricos como hojas o pesos. Estos valores de peso se pueden regularizar utilizando los diferentes métodos de regularización, como los pesos de regularización L1 o L2, lo que penaliza el algoritmo de refuerzo radiante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb390ce-2b48-44c4-b3c7-4637a4fd8aa7",
   "metadata": {},
   "source": [
    "#### Restricciones de árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419e2dc-11f7-4695-a2ce-a3e47a33bd49",
   "metadata": {},
   "source": [
    "El árbol de decisión se puede restringir de numerosas formas, como limitar la profundidad del árbol, imponer un límite al número de hojas o nodes del árbol, limitar el número de observaciones por división y limitar el número de observaciones entrenadas. En general, cuantas más restricciones utilice al crear árboles, más árboles necesitará el modelo para ajustar correctamente los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b9ab2-360b-44f4-9dc6-e3dab8578766",
   "metadata": {},
   "source": [
    "#### Muestreo aleatorio / Impulso estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531a814-373c-4ef3-83b6-8681708e2e68",
   "metadata": {},
   "source": [
    "Tomar submuestras aleatorias del conjunto de datos de entrenamiento, una técnica conocida como aumento de gradiente estocástico, también puede ayudar a prevenir el sobreajuste. Esta técnica reduce esencialmente la fuerza de la correlación entre árboles.\n",
    "\n",
    "Hay varias formas de submuestrear el conjunto de datos, como submuestrear columnas antes de cada división, submuestrear columnas antes de crear un árbol, como filas de submuestreo antes de crear un árbol. En general, el submuestreo a tasas grandes que no superen el 50% de los datos parece ser beneficioso para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995aa8d-8410-4f84-8eba-49f2a52f8e77",
   "metadata": {},
   "source": [
    "#### Actualizaciones ponderadas / por contracción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d43cf-74cb-4394-8a27-b62a295f3f93",
   "metadata": {},
   "source": [
    "Debido a que las predicciones de cada árbol se suman, las contribuciones de los árboles pueden inhibirse o ralentizarse mediante una técnica llamada contracción. Se ajusta una «tasa de aprendizaje», y cuando se reduce la tasa de aprendizaje, se deben agregar más árboles al modelo. Esto hace que el modelo necesite más tiempo para entrenarse.\n",
    "\n",
    "Existe una compensación entre la tasa de aprendizaje y la cantidad de árboles necesarios, por lo que tendrá que experimentar para encontrar los mejores valores para cada uno de los parámetros, pero los valores pequeños menores a 0.1 o valores entre 0.1 y 0.3 a menudo funcionan bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341daeca-b709-44fa-b7bd-fdcedd0f78d8",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c3e57-a1bd-4ac6-8f78-cfe56688c15f",
   "metadata": {},
   "source": [
    "XGBoost es una versión refinada y personalizada de un sistema de árbol de decisiones que impulsa el gradiente, creado teniendo en cuenta el rendimiento y la velocidad. XGBoost en realidad significa «eXtreme Gradient Boosting» y se refiere al hecho de que los algoritmos y métodos se han personalizado para llevar el límite de lo que es posible para los algoritmos de aumento de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02423fb-24d7-4ce5-a20d-b1b23894b9ad",
   "metadata": {},
   "source": [
    "## Implementación de un clasificador de aumento de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a06e9a-a415-4933-851d-e788a5056fa9",
   "metadata": {},
   "source": [
    "### Clasificador de refuerzo regular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287298e-30a5-4712-8b85-7c926d07b816",
   "metadata": {},
   "source": [
    "Para empezar, debemos elegir un conjunto de datos en el que trabajar y, para este ejemplo, usaremos el conjunto de datos Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3322874-38a2-4ae4-b242-344e71e5e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando librerias(Bibliotecas)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cf599d-33e9-426d-8436-5e648e9348ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de datos\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08565554-d723-4ed3-ba2e-7cfeb3ce92f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55aafa50-ea1b-4f1a-ac06-ecdc1c5a8cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d578c26-393c-4099-a287-cd4227842876",
   "metadata": {},
   "source": [
    "### Exploracion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318d4cf3-be2e-4e4d-a4a8-fab9650ae247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que columnas tienen el dataset?\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056f6c5e-5f96-4c11-8247-da4d8c248c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1772ac2-965e-4a3b-9054-b29ef497bb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que tamaño tienen los datos? aparece numero de filas x columnas\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ef03a4-0159-46b6-be09-96ae1896d8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041b78c9-2e90-4dd5-ba9c-3ff8b69332d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# hay valores nulos en los datos?\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af67fe-ec89-41ff-9371-9a0b25afbe37",
   "metadata": {},
   "source": [
    "Se observa que hay valores nulos en Age, Cabin y Embared; como metodo de accion se puede imputar datos o en\n",
    "su defecto eliminar registros, aunque estas dos ultimas acciones se deben analizar con precaucion toda vez que\n",
    "puede afectar la alteracion de los resultados esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e393c15d-6a16-4e75-9dcf-1f9917b36b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe79c2-5625-4fd6-b2e8-c5090e1908a8",
   "metadata": {},
   "source": [
    "Igualmente para test_data se observan datos nulos en algunas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9bf038-dd5a-44f3-b928-f26318e3ee73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como se distribuyen las variables numericas\n",
    "# count: conteo, mean: media, std: desviacion estandar, min: minimos, max: maximos, cuantiles: 25% - 50% - 75%\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e778d08-ab59-46aa-b74f-18963dad5492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5497c62-f27c-4f4b-92e1-9ff6c349d11f",
   "metadata": {},
   "source": [
    "### Preparacion de datos para la informacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00662132-9486-4a45-a6db-f5239072772c",
   "metadata": {},
   "source": [
    "Es posible que debamos hacer un procesamiento previo de los datos. Establezcamos el índice como PassengerIdy luego seleccionemos nuestras características y etiquetas. Nuestros datos de etiqueta, los ydatos son la Survivedcolumna. Así que crearemos su propio marco de datos y luego lo eliminaremos de las funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "323ded6e-8c2b-4195-89ab-459f6bd01e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]\n",
    "train_data.drop(labels=\"Survived\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98008f50-8dba-4317-8688-1eee255f57d9",
   "metadata": {},
   "source": [
    "Ahora tenemos que crear un nuevo conjunto de datos concatenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b81619b-6590-4f40-985f-93a978156491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SILS\\AppData\\Local\\Temp\\ipykernel_13360\\1902146627.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  full_data = train_data.append(test_data)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    full_data = train_data.append(test_data)\n",
    "except SomeException:\n",
    "    print(\"Cuidado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c40981-68e2-4544-85b4-7849486d7fdd",
   "metadata": {},
   "source": [
    "Eliminemos las columnas que no sean necesarias o útiles para el entrenamiento, aunque puede dejarlas y ver cómo afectan las cosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24f96b6a-f508-41e9-b03a-1613404a3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"Name\", \"Age\", \"SibSp\", \"Ticket\", \"Cabin\", \"Parch\", \"Embarked\"]\n",
    "full_data.drop(labels=drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d47cad-9bd6-40d9-a341-e47581968de4",
   "metadata": {},
   "source": [
    "Cualquier dato de texto debe convertirse en números que nuestro modelo pueda usar, así que cambiemos eso ahora. También llenaremos las celdas vacías con 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a82164e4-bd0a-4310-ac51-6f755b66e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.get_dummies(full_data, columns=[\"Sex\"])\n",
    "full_data.fillna(value=0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511a734-8a2d-48c0-b539-0a188be3e12c",
   "metadata": {},
   "source": [
    "Dividamos los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4a4eab-7d85-432f-a99e-13040ad4d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_data.values[0:891]\n",
    "X_test = full_data.values[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023b4dd-1154-4215-978d-e48dac86900d",
   "metadata": {},
   "source": [
    "Ahora escalaremos nuestros datos creando una instancia del escalador y escalando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "341052d7-94c6-4856-b8cc-3577747b0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6697fa-2020-475f-afaf-3285c700ba52",
   "metadata": {},
   "source": [
    "Ahora podemos dividir los datos en conjuntos de entrenamiento y prueba. También establezcamos una semilla (para que pueda replicar los resultados) y seleccionemos el porcentaje de datos para probar en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4202cf2-e9b8-4bf6-bc19-cd550b02ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 12  \n",
    "test_size = 0.30  \n",
    "  \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,  \n",
    "    test_size=test_size, random_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224c9a3-2b67-41c4-8633-408351ff05ee",
   "metadata": {},
   "source": [
    "Ahora podemos intentar establecer diferentes tasas de aprendizaje, de modo que podamos comparar el rendimiento del clasificador a diferentes tasas de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75aae322-86d1-42c2-9c91-d779dae7534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.801\n",
      "Accuracy score (validation): 0.731\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.814\n",
      "Accuracy score (validation): 0.731\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.812\n",
      "Accuracy score (validation): 0.724\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.835\n",
      "Accuracy score (validation): 0.750\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.864\n",
      "Accuracy score (validation): 0.772\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.875\n",
      "Accuracy score (validation): 0.754\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.875\n",
      "Accuracy score (validation): 0.739\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537c881-358a-4a15-a614-3f29a8e4c370",
   "metadata": {},
   "source": [
    "Estamos interesados principalmente en la precisión del clasificador en el conjunto de validación, pero parece que una tasa de aprendizaje de 0,5 nos da el mejor rendimiento en el conjunto de validación y un buen rendimiento en el conjunto de entrenamiento.\n",
    "\n",
    "Ahora podemos evaluar el clasificador comprobando su precisión y creando una matriz de confusión. Creemos un nuevo clasificador y especifiquemos la mejor tasa de aprendizaje que descubrimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39493214-7f64-402e-87d9-9ab06b8ba62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[142  19]\n",
      " [ 42  65]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       161\n",
      "           1       0.77      0.61      0.68       107\n",
      "\n",
      "    accuracy                           0.77       268\n",
      "   macro avg       0.77      0.74      0.75       268\n",
      "weighted avg       0.77      0.77      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "gb_clf2.fit(X_train, y_train)\n",
    "predictions = gb_clf2.predict(X_val)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a1830-2414-466e-b6f4-ea67fa19621e",
   "metadata": {},
   "source": [
    "### Clasificador XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87820ef5-05b5-4b94-90ff-6b6efe6b48b6",
   "metadata": {},
   "source": [
    "Ahora experimentaremos con el clasificador XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "780884c3-b147-4053-9dfb-82424ede8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las librerias\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ValueError:\n",
    "    print(\"Cuidado!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fa889-1585-4884-a0c1-a8bb3023dc91",
   "metadata": {},
   "source": [
    "Dado que nuestros datos ya están preparados, solo necesitamos ajustar el clasificador con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d3da38d-d3ff-4ba5-a538-f0ffdd220214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:37:04] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    xgb_clf = XGBClassifier()\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "except ValueError:\n",
    "    print(\"Cuidado!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63fd9870-1168-493f-b1ac-00af55d2bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746268656716418\n"
     ]
    }
   ],
   "source": [
    "score = xgb_clf.score(X_val, y_val)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd07c1c-c6d8-4bdc-88a1-bda865780289",
   "metadata": {},
   "source": [
    "Alternativamente, puede predecir los X_valdatos y luego verificar la precisión con el y_valuso de accuracy_score. Debería darte el mismo tipo de resultado.\n",
    "\n",
    "La comparación de la precisión de XGboost con la precisión de un clasificador de gradiente regular muestra que, en este caso, los resultados fueron muy similares. Sin embargo, este no siempre será el caso y, en diferentes circunstancias, uno de los clasificadores podría funcionar mejor que el otro. Intente variar los argumentos en este modelo para ver cómo difiere el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f71452-db44-4171-8ab0-a016d93f46b2",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e8bb0-5795-4ae8-9787-479cf8252e2b",
   "metadata": {},
   "source": [
    "Los modelos de aumento de gradiente son algoritmos poderosos que se pueden usar tanto para tareas de clasificación como de regresión. Los modelos de aumento de gradiente pueden funcionar increíblemente bien en conjuntos de datos muy complejos, pero también son propensos a sobreajustarse, lo que se puede combatir con varios de los métodos descritos anteriormente. Los clasificadores de aumento de gradiente también son fáciles de implementar en Scikit-Learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
